import torch
import numpy as np
from diffusers import UNet2DConditionModel, AutoencoderKL, EulerDiscreteScheduler
from transformers import CLIPTextModel, CLIPTokenizer
from peft import PeftModel
from PIL import Image

# --- Cáº¥u hÃ¬nh ---
base_model_id = "runwayml/stable-diffusion-v1-5"
merged_model_dir = "./merged_model"
device = "cuda"
dtype = torch.float16

print("--- Báº¯t Ä‘áº§u táº¡o Ground Truth tá»« PyTorch ---")

# --- 1. Táº£i cÃ¡c thÃ nh pháº§n Ä‘Ã£ Ä‘Æ°á»£c há»£p nháº¥t ---
print("Táº£i Tokenizer...")
tokenizer = CLIPTokenizer.from_pretrained(base_model_id, subfolder="tokenizer")

print("Táº£i Text Encoder vÃ  Ã¡p dá»¥ng LoRA...")
text_encoder = CLIPTextModel.from_pretrained(base_model_id, subfolder="text_encoder", torch_dtype=dtype)
text_encoder = PeftModel.from_pretrained(text_encoder, f"{merged_model_dir}/text_encoder").to(device)
text_encoder = text_encoder.merge_and_unload() # Há»£p nháº¥t thÃ nh model thuáº§n tÃºy

print("Táº£i UNet Ä‘Ã£ há»£p nháº¥t...")
unet = UNet2DConditionModel.from_pretrained(f"{merged_model_dir}/unet", torch_dtype=dtype, low_cpu_mem_usage=False).to(device)

print("Táº£i VAE...")
vae = AutoencoderKL.from_pretrained(f"{merged_model_dir}/vae", torch_dtype=dtype).to(device)

print("Táº£i Scheduler...")
scheduler = EulerDiscreteScheduler.from_pretrained(base_model_id, subfolder="scheduler")

# --- 2. Táº¡o cÃ¡c file debug .npy ---
prompt = "a cute cat, high quality"
input_ids = tokenizer(prompt, return_tensors="pt", padding="max_length", truncation=True, max_length=77).input_ids.to(device)

print("Táº¡o debug_hidden_states.npy...")
with torch.no_grad():
    hidden_states = text_encoder(input_ids)[0].cpu().numpy()
np.save("debug_hidden_states.npy", hidden_states)

print("Táº¡o debug_initial_latents.npy vÃ  debug_pytorch_noise_pred.npy...")
# Táº¡o latents ban Ä‘áº§u cÃ³ thá»ƒ tÃ¡i táº¡o Ä‘Æ°á»£c Ä‘á»ƒ so sÃ¡nh chÃ­nh xÃ¡c
generator = torch.Generator(device=device).manual_seed(0)
latents = torch.randn((1, 4, 64, 64), generator=generator, device=device, dtype=dtype)
np.save("debug_initial_latents.npy", latents.cpu().numpy())

t = torch.tensor([999], dtype=torch.int64).to(device)
with torch.no_grad():
    noise_pred = unet(latents, t, encoder_hidden_states=torch.from_numpy(hidden_states).to(device)).sample.cpu().numpy()
np.save("debug_pytorch_noise_pred.npy", noise_pred)

print("âœ… ÄÃ£ táº¡o xong cÃ¡c file .npy.")

# --- 3. Táº¡o áº£nh máº«u Ä‘á»ƒ kiá»ƒm tra báº±ng máº¯t thÆ°á»ng ---
print("Táº¡o áº£nh máº«u pytorch_merged_output.png...")
num_inference_steps = 50
scheduler.set_timesteps(num_inference_steps)
latents = torch.randn((1, 4, 64, 64), generator=generator, device=device, dtype=dtype) # TÃ¡i táº¡o láº¡i latents

with torch.no_grad():
    for t in scheduler.timesteps:
        latent_model_input = latents
        noise_pred = unet(latent_model_input, t, encoder_hidden_states=torch.from_numpy(hidden_states).to(device)).sample
        latents = scheduler.step(noise_pred, t, latents).prev_sample
    
    # Decode
    latents = 1 / vae.config.scaling_factor * latents
    image = vae.decode(latents).sample
    image = (image / 2 + 0.5).clamp(0, 1)
    image = image.cpu().permute(0, 2, 3, 1).numpy()
    image = (image[0] * 255).round().astype("uint8")
    image = Image.fromarray(image)

image.save("pytorch_merged_output.png")
print("âœ… ÄÃ£ lÆ°u áº£nh káº¿t quáº£ tá»« PyTorch: pytorch_merged_output.png")
print("\nðŸŽ‰ HoÃ n táº¥t! BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y script debug_unet.py.")

'''
âŒ Lá»–I NGHIÃŠM TRá»ŒNG: Output cá»§a UNet TensorRT chá»©a NaN hoáº·c Inf!
ÄÃ¢y lÃ  báº±ng chá»©ng khÃ´ng thá»ƒ chá»‘i cÃ£i.
Diá»…n giáº£i káº¿t quáº£
Script test_pytorch_merge.py Ä‘Ã£ thÃ nh cÃ´ng: NÃ³ Ä‘Ã£ táº¡o ra cÃ¡c file debug_*.npy vÃ  má»™t áº£nh Ä‘áº¹p (pytorch_merged_output.png). Äiá»u nÃ y chá»©ng tá» model PyTorch sau khi tÃ­ch há»£p LoRA hoáº¡t Ä‘á»™ng hoÃ n háº£o.
Script debug_unet.py Ä‘Ã£ tháº¥t báº¡i tháº£m háº¡i: Khi báº¡n Ä‘Æ°a chÃ­nh xÃ¡c cÃ¹ng má»™t Ä‘áº§u vÃ o (latents, timestep, hidden_states) vÃ o engine UNet FP16, Ä‘áº§u ra cá»§a nÃ³ khÃ´ng pháº£i lÃ  má»™t dá»± Ä‘oÃ¡n nhiá»…u há»£p lá»‡, mÃ  lÃ  cÃ¡c giÃ¡ trá»‹ vÃ´ nghÄ©a (NaN - Not a Number, Inf - Infinity).
Káº¿t luáº­n cuá»‘i cÃ¹ng: Váº¥n Ä‘á» náº±m á»Ÿ quÃ¡ trÃ¬nh build engine UNet vá»›i cá» --fp16. CÃ¡c trá»ng sá»‘ cá»§a UNet (ká»ƒ cáº£ sau khi Ä‘Ã£ tÃ­ch há»£p LoRA) khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i viá»‡c giáº£m Ä‘á»™ chÃ­nh xÃ¡c xuá»‘ng 16-bit. CÃ¡c phÃ©p tÃ­nh bÃªn trong engine Ä‘Ã£ bá»‹ sá»¥p Ä‘á»•, gÃ¢y ra lá»—i sá»‘ há»c vÃ  táº¡o ra dá»¯ liá»‡u "rÃ¡c".
ÄÃ¢y chÃ­nh lÃ  nguyÃªn nhÃ¢n gá»‘c rá»… cá»§a viá»‡c báº¡n nháº­n Ä‘Æ°á»£c áº£nh mÃ u xÃ¡m.

-> thá»­ chuyá»ƒn unet sang fp32
'''